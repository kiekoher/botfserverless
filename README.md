# EVA: Plataforma de Agentes de Ventas con IA

EVA es una plataforma SaaS multi-tenant para desplegar agentes de ventas impulsados por inteligencia artificial. Este repositorio contiene la infraestructura completa y contenerizada de la plataforma, dise침ada para un despliegue automatizado y escalable.

El sistema sigue una arquitectura de microservicios y est치 completamente orquestado por Docker Compose. Todos los servicios, incluido el frontend, est치n dise침ados para ejecutarse en un 칰nico servidor de producci칩n.

## Descripci칩n General de la Arquitectura

-   **`frontend` (Next.js):** El panel de control orientado al usuario para gestionar agentes, ver conversaciones y configurar cuentas. Se sirve como un contenedor Docker.
-   **`main-api` (Python/FastAPI):** El n칰cleo de la aplicaci칩n. Maneja toda la l칩gica de negocio, gestiona el enrutamiento de modelos de IA y sirve la API REST principal. Se comunica con otros servicios de forma as칤ncrona.
-   **`whatsapp-gateway` (Node.js):** El punto de entrada para todos los mensajes de usuario desde WhatsApp. Act칰a como un puente, recibiendo mensajes, subiendo archivos multimedia y publicando eventos en un stream de Redis. **Nota:** Este servicio utiliza la librer칤a `whatsapp-web.js`, que no es una API oficial de WhatsApp. Su uso ha sido evaluado y aceptado como un riesgo de negocio para la fase actual del proyecto.
-   **`transcription-worker` (Python):** Un trabajador dedicado que escucha los mensajes de audio en el stream de Redis, los transcribe usando un modelo local `faster-whisper` para garantizar la privacidad y un costo fijo, y publica el texto de vuelta para que `main-api` lo procese.
-   **`embedding-worker` (Python):** Procesa documentos entrantes, genera embeddings y actualiza el estado de los archivos en Supabase.
-   **`dlq-monitor` (Python):** Supervisa la Dead Letter Queue en Redis y registra los mensajes fallidos para su posterior an치lisis.
-   **`traefik` (Traefik):** Un proxy inverso que enruta el tr치fico entrante al servicio apropiado (`frontend` o `main-api`) y maneja la terminaci칩n SSL con certificados auto-renovables de Let's Encrypt.
-   **`redis` (Redis):** Utilizado como un message broker de alto rendimiento (a trav칠s de Redis Streams) para facilitar la comunicaci칩n as칤ncrona entre los microservicios.
-   **`loki` & `promtail`:** Una pila de logging completa para agregar y ver los logs de todos los contenedores en ejecuci칩n.

---

## 游 C칩mo Empezar

### 1. Prerrequisitos

-   Docker & Docker Compose
-   Un nombre de dominio registrado que apunte a la direcci칩n IP de su servidor.
-   Una cuenta de Docker Hub para el almacenamiento de im치genes.

### 2. Variables de Entorno

Todo el sistema se configura mediante variables de entorno. Para desarrollo local o producci칩n, copie el archivo de ejemplo:

```bash
cp .env.example .env.prod
```

Luego, complete los valores en `.env.prod`. Consulte los comentarios en el archivo como gu칤a para cada variable. Para cambiar los modelos usados por Gemini, establezca `GEMINI_EMBED_MODEL` y `GEMINI_CHAT_MODEL`.

Estas variables controlan:

- `GEMINI_EMBED_MODEL`: modelo utilizado para generar embeddings.
- `GEMINI_CHAT_MODEL`: modelo utilizado para respuestas conversacionales.
- `NEXT_PUBLIC_API_URL`: URL base de la API (por ejemplo `http://main-api:8000/api/v1`).
- `OPENAI_EMBED_MODEL`: modelo de embeddings usado por los servicios que consumen OpenAI (por defecto `text-embedding-3-large`).

### 3. Ejecutando el Sistema Localmente

Para construir y ejecutar todos los servicios en modo detached, use el archivo docker-compose de producci칩n, que es la 칰nica fuente de verdad para la arquitectura del proyecto:

```bash
docker-compose -f docker-compose.prod.yml up --build -d
```

Para ver los logs de un servicio espec칤fico (por ejemplo, `whatsapp-gateway` para escanear el c칩digo QR):

```bash
docker-compose -f docker-compose.prod.yml logs -f whatsapp-gateway
```

## 游닄 Documentaci칩n de la API

El servicio `main-api` expone documentaci칩n interactiva generada autom치ticamente por FastAPI en la ruta `/docs`.
Una vez que los contenedores est칠n en ejecuci칩n, puede accederse a trav칠s de:

```
http://<host>:8000/docs
```

Esta interfaz permite explorar los endpoints disponibles y probarlos directamente desde el navegador.

---

## 游빍 Pruebas

El proyecto incluye una suite de pruebas automatizadas tanto para el backend como para el frontend, que se ejecuta autom치ticamente en el pipeline de CI/CD.

Para correr las pruebas de backend fuera de contenedores, instale las dependencias necesarias y ejecute `pytest`:

```bash
pip install -r requirements.txt
pytest
```

Para ejecutar las pruebas manualmente dentro de los contenedores, primero aseg칰rese de que los servicios est칠n en funcionamiento:

```bash
# Iniciar todos los servicios
docker-compose -f docker-compose.prod.yml up -d

# Esperar unos segundos para que los servicios se inicien, luego ejecutar las pruebas
```

-   **Pruebas de Backend (`main-api`):**
    ```bash
    docker-compose -f docker-compose.prod.yml exec main-api pytest
    ```

-   **Pruebas de Frontend:**
    ```bash
    docker-compose -f docker-compose.prod.yml exec frontend npm test
    ```

---

## 游 Despliegue en Producci칩n (CI/CD)

Este proyecto est치 configurado para **despliegues totalmente automatizados** a un entorno de producci칩n usando GitHub Actions.

### C칩mo Funciona

El pipeline de despliegue est치 definido en `.github/workflows/deploy.yml` y se activa en cada push a la rama `main`. Consta de tres etapas:

1.  **Test y Lint:** Ejecuta autom치ticamente todas las pruebas y verificaciones de calidad de c칩digo para todos los servicios. Este trabajo debe pasar antes de que el despliegue pueda continuar.
2.  **Build y Push:** Construye nuevas im치genes de Docker para todos los servicios, las etiqueta con `latest` y las sube a su registro de Docker Hub.
3.  **Deploy:** Se conecta al servidor de producci칩n a trav칠s de SSH, crea el archivo `.env.prod` a partir de los GitHub Secrets, descarga las 칰ltimas im치genes de Docker desde Docker Hub y reinicia los servicios usando `docker-compose.prod.yml`.

### Configuraci칩n de GitHub Secrets

Para que la automatizaci칩n funcione, debe configurar los siguientes secrets en la configuraci칩n de su repositorio de GitHub en **Settings > Secrets and variables > Actions**:

-   `DOCKERHUB_USERNAME`: Su nombre de usuario de Docker Hub.
-   `DOCKERHUB_TOKEN`: Un token de acceso de Docker Hub con permisos de lectura/escritura.
-   `SSH_HOST`: La direcci칩n IP o el dominio de su servidor de producci칩n.
-   `SSH_USERNAME`: El nombre de usuario para el acceso SSH.
-   `SSH_PRIVATE_KEY`: La clave SSH privada para acceder al servidor.
-   `DOMAIN_NAME`: El nombre de dominio para su servicio (por ejemplo, `eva.yourcompany.com`).
-   `CERTBOT_EMAIL`: La direcci칩n de correo electr칩nico para las notificaciones de Let's Encrypt.
-   `GRAFANA_BASIC_AUTH_USER`: Credenciales para la autenticaci칩n b치sica de Grafana (formato `user:hashed_password`).
-   Todos los dem치s secrets requeridos por la aplicaci칩n (por ejemplo, `SUPABASE_URL`, `GOOGLE_API_KEY`, etc.).

Con esta configuraci칩n, su infraestructura est치 totalmente automatizada. Simplemente haga push a `main`, y sus cambios ser치n probados y desplegados.

---

## 游 Backups y Recuperaci칩n

Una estrategia de backups robusta es cr칤tica para la resiliencia de la plataforma. A continuaci칩n se describe el plan de backups para los dos componentes con estado del sistema: la base de datos de Supabase y los vol칰menes de Docker.

### 1. Base de Datos (Supabase)

Supabase proporciona backups autom치ticos diarios en sus planes de pago.

-   **Acci칩n Requerida:**
    1.  Aseg칰rese de que su proyecto de Supabase est치 en un plan que incluya backups autom치ticos.
    2.  Vaya al **Dashboard de su proyecto > Database > Backups**.
    3.  Verifique que los backups diarios est치n activados.
    4.  Familiar칤cese con el proceso de "Point-in-Time Recovery (PITR)" que ofrece Supabase para restaurar la base de datos a un punto espec칤fico en el tiempo.

### 2. Vol칰menes de Docker (Redis y Sesi칩n de WhatsApp)

Los datos de la sesi칩n de WhatsApp y los datos de Redis (si la persistencia est치 habilitada) se guardan en vol칰menes de Docker en el servidor host.

-   **Estrategia de Backup Automatizada:**
    El sistema incluye un servicio de backup (`backup`) totalmente automatizado y contenerizado que se ejecuta diariamente a las 3:00 AM UTC. Este servicio se encarga de:
    1.  Detener de forma segura los servicios con estado (`redis`, `whatsapp-gateway`, etc.).
    2.  Crear un archivo `.tar.gz` comprimido con los datos de los vol칰menes de Docker.
    3.  Reiniciar los servicios detenidos inmediatamente despu칠s de la copia.
    4.  (Opcional) Subir el backup a un almacenamiento externo compatible con S3 (como Cloudflare R2) usando `rclone`.
    5.  Rotar y eliminar los backups locales antiguos para evitar que el disco se llene.

-   **Acci칩n Requerida:**
    1.  **No se requiere configuraci칩n manual de `cron` en el host.** El proceso est치 100% gestionado dentro del entorno de Docker.
    2.  Para activar los backups externos, configure las variables de entorno `R2_BUCKET_PATH`, `R2_REMOTE_NAME` y las credenciales de `rclone` correspondientes en su archivo `.env.prod`.

---

## 游늯 Licencia

Este proyecto se distribuye bajo la licencia [MIT](LICENSE).
